import pandas as pd
import numpy
from selenium import webdriver
import re
import time
import csv
import datetime as dt
from tqdm import tqdm
import requests
#무신사 id,emg
dt = dt.datetime.now()
# pandas_csv_path =r'C:\Users\Home\PycharmProjects\pythonProject1\Review\mu'.format(dt.strftime("%Y_%m_%d"))
# prod_id_csv = pd.read_csv(pandas_csv_path)
# moshinsa_all_model = prod_id_csv['prod_id'].head(2)
prod_id_csv = pd.read_csv('musinsa_name_id2020_10_02.csv')
moshinsa_all_model = prod_id_csv['prod_id'].head(2)

options = webdriver.ChromeOptions()
options.add_argument('headless')
options.add_argument('window-size=1920x1080')
options.add_argument("disable-gpu")
options.add_argument(f'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36')
driver = webdriver.Chrome(r'C:\Users\Home\PycharmProjects\pythonProject1\chromedriver.exe',options=options)

style_list = ['style','photo','goods']
moshinsa_rvw_list = []
rvw_img_url_list = []
for style in style_list:
    page_num = 0
    for mosinsa_prod_id in moshinsa_all_model:
        while True:
            page_num = page_num + 1
            url = 'https://store.musinsa.com/app/reviews/goods_estimate_list/'+str(style)+'/'+str(mosinsa_prod_id)+'/0/'+str(page_num)
            driver.get(url)
            prod_rvw_date = driver.find_elements_by_css_selector('body > div > div > div > div.postRight > div > div.profile > p > span.date.last')
            prod_name = driver.find_elements_by_css_selector('body > div > div > div > div.postRight > div > div.connect_product.estimate-item > div.connect_review_info > div > a.list_info.p_name')
            prod_cust_buy_size = driver.find_elements_by_css_selector('body > div > div > div > div.postRight > div > div.connect_product.estimate-item > div.connect_review_info > p')
            prod_size_jud = driver.find_elements_by_css_selector('body > div > div > div > div.postRight > div > div.prd-level-each > ul')
            prod_rvw = driver.find_elements_by_css_selector('body > div > div > div > div.postRight > div > div.pContent > div.summary > div > div.pContent_text > span')
            mosinsa_img_list = driver.find_elements_by_class_name('musinsa-gallery-images')
            for mosinsa_img_one in mosinsa_img_list:
                mosinsa_img_url = mosinsa_img_one.get_attribute('src')
                rvw_img_url_list.append(mosinsa_img_url)
            try:
                no_data = driver.find_element_by_class_name('mypage_review_none')
                if no_data != None:
                    break
            except:
                pass
            for prod_size_jud_split in prod_size_jud:
                prod_size_jud_text = prod_size_jud_split.text
                try:
                    test = prod_size_jud_text.split('\n')
                    size = test[0]
                    brightness = test[1]
                    color = test[2]
                    footwidth = test[3]
                    ignition = test[4]
                except:
                    pass
            for q,w,e,r in zip(prod_rvw_date,prod_name,prod_cust_buy_size,prod_rvw):
                moshinsa_rvw_list.append([q.text,w.text,e.text,size,brightness,color,footwidth,ignition,r.text])

        n = 0
        for url in rvw_img_url_list:
            n = n + 1
            r = requests.get(url)
            file = open(r'C:\Users\Home\PycharmProjects\pythonProject1\Mosinsaimg\mosinsarvw_img{}.jpg'.format(str(mosinsa_prod_id) +str('No') + str(n)),'wb')
            file.write(r.content)
            file.close()

Refilename = 'mosinsarev{}.csv'.format(dt.strftime("%Y_%m_%d"))
f = open(Refilename, 'w', encoding='utf-8', newline='')
csvWriter = csv.writer(f)
csvWriter.writerow(['prod_date','prod_name','prod_cust_buy_size','prod_size','prod_brightness','prod_color','prod_footwidth','prod_ignition','prod_rvw'])
for w in moshinsa_rvw_list:
    csvWriter.writerow(w)
f.close()
print('완료')